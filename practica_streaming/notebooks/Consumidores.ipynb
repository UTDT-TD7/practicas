{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción: productores y consumidores usando tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "SERVER = \"kafka_b:9094\"\n",
    "consumer = KafkaConsumer(\n",
    "    \"website_events\", \n",
    "    bootstrap_servers=SERVER,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.poll(timeout_ms=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'website_events'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.subscription()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congelamos el proceso hasta recibir un mensaje y luego volvemos el control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsumerRecord(topic='website_events', partition=1, offset=58, timestamp=1719274347490, timestamp_type=0, key=None, value=b\"{'type': 'click', 'location': '/index.html'}\", headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=44, serialized_header_size=-1)\n"
     ]
    }
   ],
   "source": [
    "for event in consumer:\n",
    "    print(event)\n",
    "    # Generalmente continuamos procesando eventos, en un loop infinito.\n",
    "    # Esperar sólo un mensaje lo podemos hacer con .poll()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que ya se configuran particiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El consumidor reporta el offset que observa al broker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recibamos unos mensajes más ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, event in enumerate(consumer):\n",
    "    if i >= 4:\n",
    "        break\n",
    "\n",
    "print(\"Terminado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el nuevo offset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event.offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el estado de las particiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TopicPartition(topic='website_events', partition=0): 65,\n",
       " TopicPartition(topic='website_events', partition=1): 66}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka import TopicPartition\n",
    "from kafka import KafkaProducer\n",
    "producer = KafkaProdu\n",
    "partitions = []\n",
    "for partition in consumer.partitions_for_topic(\"website_events\"):\n",
    "    partitions.append(TopicPartition(\"website_events\", partition))\n",
    "    \n",
    "end_offsets = consumer.end_offsets(partitions)\n",
    "end_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto indica el offset del siguiente mensaje de la partición a recibir. Los offsets son compartidos a nivel tópico."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particionamiento\n",
    "\n",
    "Para implementar distribución de carga "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer0 = KafkaConsumer(bootstrap_servers=SERVER)\n",
    "consumer1 = KafkaConsumer(bootstrap_servers=SERVER)\n",
    "\n",
    "consumer0.assign([TopicPartition(topic=\"metrics\", partition=0)])\n",
    "consumer1.assign([TopicPartition(topic=\"metrics\", partition=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aseguramos el registro en el broker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer0.poll(timeout_ms=1000)\n",
    "consumer1.poll(timeout_ms=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de hacer send de un mensaje en cada uno recibimos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TopicPartition(topic='metrics', partition=0): [ConsumerRecord(topic='metrics', partition=0, offset=1, timestamp=1719276267314, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer0.poll(timeout_ms=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TopicPartition(topic='metrics', partition=1): [ConsumerRecord(topic='metrics', partition=1, offset=1, timestamp=1719276270398, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer1.poll(timeout_ms=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grupos de consumidores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los grupos son una forma de rebalancear automáticamente las particiones entre consumidores que entran y salen del mismo. \n",
    "\n",
    "Permiten de manera más transparente mezclar los patrones de cola simple y de pubsub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registremos dos consumidores en el mismo grupo, uno en este notebook y otro en el notebook GrupoConsumidor1. \n",
    "\n",
    "(Separamos en dos notebooks que hacen polling continuamente para evitar que Kafka rebalancee constantemente el grupo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConsumerRecord(topic='metrics', partition=0, offset=7, timestamp=1719277990174, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=0, offset=8, timestamp=1719278028241, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=0, offset=9, timestamp=1719278058128, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=0, offset=10, timestamp=1719278059425, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=0, offset=11, timestamp=1719278060021, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=0, offset=12, timestamp=1719278220211, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=0, offset=13, timestamp=1719278223647, timestamp_type=0, key=b'0', value=b'hola', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=4, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=12, timestamp=1719278275729, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=13, timestamp=1719278277288, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=14, timestamp=1719278277753, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=15, timestamp=1719278278191, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=16, timestamp=1719278278617, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=17, timestamp=1719278279048, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=18, timestamp=1719278279471, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=19, timestamp=1719278279892, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=20, timestamp=1719278280364, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n",
      "ConsumerRecord(topic='metrics', partition=1, offset=21, timestamp=1719278280849, timestamp_type=0, key=b'1', value=b'mundo', headers=[], checksum=None, serialized_key_size=1, serialized_value_size=5, serialized_header_size=-1)\n"
     ]
    }
   ],
   "source": [
    "group_consumer0 = KafkaConsumer(\n",
    "    \"metrics\", \n",
    "    group_id=\"spice1\",\n",
    "    bootstrap_servers=SERVER,\n",
    "    client_id=\"client1\",\n",
    ")\n",
    "\n",
    "for msg in group_consumer0:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tiramos el otro notebook eventualmente veremos que este toma las de la otra partición también :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
